#!/usr/bin/python3 -u

from __future__ import annotations

import os
import sys
import traceback
import logging
import time
from collections import defaultdict
from typing import Set, Dict, List, Any, Optional, Tuple
from pathlib import Path
import graphlib
import json

import prctl
import structlog

topdir = Path(__file__).resolve().parent
pythonpath_l = []
if (topdir / 'lilac2').exists():
  # In-tree
  p = str(topdir)
  sys.path.append(p)
  pythonpath_l.append(p)
  p = str(topdir / 'lilac2' / 'vendor')
  sys.path.append(p)
  pythonpath_l.append(p)
else:
  # Installed as a system package
  import lilac2
  p = str(Path(lilac2.__file__).parent / 'vendor')
  sys.path.append(p)
  pythonpath_l.append(p)
pythonpath = ':'.join(pythonpath_l)
del p, pythonpath_l

from myutils import lock_file
from serializer import PickledData
from nicelogger import enable_pretty_logging

from lilac2.packages import (
  DependencyManager, get_dependency_map, get_changed_packages,
  Dependency,
)
from lilac2.cmd import (
  run_cmd, git_pull_override, git_push, pkgrel_changed,
  git_reset_hard, get_git_branch,
)
from lilac2.tools import read_config
from lilac2.repo import Repo
from lilac2.const import mydir, _G, PACMAN_DB_DIR
from lilac2.nvchecker import packages_need_update, nvtake, NvResults
from lilac2.nomypy import BuildResult, BuildReason # type: ignore
from lilac2 import pkgbuild
from lilac2.building import build_package, MissingDependencies
from lilac2 import slogconf
try:
  from lilac2 import db
except ImportError:
  class db: # type: ignore
    USE = False

config = read_config()

# Setting up enviroment variables
os.environ.update(config.get('envvars', ()))
os.environ['PATH'] = str(topdir) + ':' + os.environ['PATH']

DESTDIR = Path(config['repository'].get('destdir', '')).expanduser()
MYNAME = config['lilac']['name']

def get_bindmounts(
  bindmounts: Optional[Dict[str, str]],
) -> List[str]:
  if bindmounts is None:
    return []

  items = [(os.path.expanduser(src), dst)
           for src, dst in bindmounts.items()]
  items.sort(reverse=True)
  return [f'{src}:{dst}' for src, dst in items]

BIND_MOUNTS = get_bindmounts(config.get('bindmounts'))

# dict for perserving insertion order
building_packages: Dict[str, Tuple[()]] = {}
nvdata: Dict[str, NvResults] = {}
DEPMAP: Dict[str, Set[Dependency]] = {}
DEPENDS: Dict[str, Set[Dependency]] = {}
build_reasons: Dict[str, List[BuildReason]] = defaultdict(list)

logger = logging.getLogger(__name__)
build_logger_old = logging.getLogger('build')
build_logger = structlog.get_logger(logger_name='build')
REPO = _G.repo = Repo(config)
logdir: Path

EMPTY_COMMIT = '4b825dc642cb6eb9a060e54bf8d69288fbee4904'

def setup_build_logger() -> None:
  handler = logging.FileHandler(mydir / 'build.log')
  handler.setFormatter(logging.Formatter('[%(asctime)s] %(message)s', '%Y-%m-%d %H:%M:%S'))
  build_logger_old.addHandler(handler)

  logfile = (mydir / 'build-log.json').open('a')

  processors = [
    slogconf.exc_info,
    slogconf.add_timestamp,
    structlog.processors.format_exc_info,
    slogconf.json_renderer,
  ]

  logger_factory = structlog.PrintLoggerFactory(
    file=logfile)

  structlog.configure(
    processors = processors,
    logger_factory = logger_factory,
  )

def git_last_commit() -> str:
  cmd = ['git', 'log', '-1', '--format=%H']
  return run_cmd(cmd).strip()

def start_build(repo: Repo, failed: Set[str], built: Set[str]) -> None:
  # built is used to collect built package names
  global DEPENDS

  building_depmap = {}
  for p in building_packages:
    building_depmap[p] = DEPMAP[p]

  dep_building_map: Dict[str, Set[str]] = {}
  nonexistent: Dict[str, List[Dependency]] = defaultdict(list)
  for name, ds in building_depmap.items():
    for d in ds:
      if not d.resolve():
        if not repo.manages(d):
          logger.warning('%s depends on %s, but it\'s not managed.',
                         name, d)
          nonexistent[name].append(d)
          continue
        # we need build this too
        logger.info('build %s as a dependency of %s because no built package found',
                    d.pkgname, name)
        building_packages[d.pkgname] = ()
        build_reasons[d.pkgname].append(BuildReason.Depended(name))

    dep_building_map[name] = set()
    for x in ds:
      pkgbase = x.pkgdir.name
      dep_building_map[name].add(pkgbase)
      # a dependency may depend other packages, we need their relations
      if pkgbase in DEPMAP:
        dep_building_map[pkgbase] = {
          x.pkgdir.name for x in DEPMAP[pkgbase]}

  for name, deps in nonexistent.items():
    repo.send_error_report(
      repo.mods[name], subject='软件包 %s 的 lilac.{py,yaml} 指定了不存在的依赖',
      msg = f'软件包 {name} 的 lilac.py 或者 lilac.yaml 指定了 repo_depends，然而其直接或者间接的依赖项 {deps!r} 并不在本仓库中。'
    )

  packages = graphlib.TopologicalSorter(dep_building_map).static_order()
  # filter out already built packages
  packages = [x for x in packages if x in building_packages]

  # ensure all packages including dependents are included
  for p in packages:
    building_depmap[p] = DEPMAP[p]

  # used to decide what to install when building
  DEPENDS = building_depmap

  if db.USE:
    from sqlalchemy import delete, update
    with db.get_session() as s:
      stmt = delete(db.PkgCurrent)
      s.execute(stmt)

      for idx, pkg in enumerate(packages):
        rs = [r.to_dict() for r in build_reasons[pkg]]
        p = db.PkgCurrent(
          pkgbase = pkg,
          index = idx,
          status = 'pending',
          build_reasons = json.dumps(rs),
        )
        s.add(p)
      db.build_updated(s)

  try:
    logger.info('building these packages: %r', packages)
    for pkg in packages:
      if pkg in failed:
        # marked as failed, skip
        continue

      logger.info('building %s', pkg)
      logfile = logdir / f'{pkg}.log'

      if db.USE:
        with db.get_session() as s:
          stmt = update(
            db.PkgCurrent
          ).where(
            db.PkgCurrent.pkgbase == pkg,
          ).values(
            status = 'building',
          )
          s.execute(stmt)
          db.build_updated(s)

      r, version = build_package(
        pkg, repo.mods[pkg],
        update_info = nvdata[pkg],
        bindmounts = BIND_MOUNTS,
        depends = DEPENDS.get(pkg, ()),
        repo = REPO,
        myname = MYNAME,
        destdir = DESTDIR,
        logfile = logfile,
        pythonpath = pythonpath,
      )

      elapsed = r.elapsed
      logger.info(
        'package %s (version %s) finished in %ds with result: %r',
        pkg, version, elapsed, r,
      )

      newver = nvdata[pkg].newver
      msg = None

      if isinstance(r, BuildResult.successful):
        build_logger_old.info(
          '%s %s [%s] successful after %ds',
          pkg, newver, version, elapsed)
        build_logger.info(
          'successful', pkgbase = pkg,
          nv_version = newver, pkg_version = version, elapsed = elapsed,
        )

      elif isinstance(r, BuildResult.staged):
        build_logger_old.info(
          '%s %s [%s] staged after %ds',
          pkg, newver, version, elapsed)
        build_logger.info(
          'staged', pkgbase = pkg,
          nv_version = newver, pkg_version = version, elapsed = elapsed,
        )

      elif isinstance(r, BuildResult.skipped):
        build_logger_old.warning('%s %s skipped after %ds', pkg, newver, elapsed)
        build_logger.warning(
          'skipped', pkgbase = pkg,
          nv_version = newver, msg = r.reason, elapsed = elapsed,
        )
        msg = r.reason

      elif isinstance(r, BuildResult.failed):
        build_logger_old.error('%s %s [%s] failed after %ds', pkg, newver, version, elapsed)
        assert r.error is not None

        if isinstance(r.error, Exception):
          e = r.error
          build_logger.error(
            'failed', pkgbase = pkg,
            nv_version = newver, elapsed = elapsed, exc_info = e,
          )
          msg = repr(e)
          mod = repo.mods[pkg]

          if isinstance(e, MissingDependencies):
            faileddeps = e.deps & failed
            repo.send_error_report(
              mod, subject='%s 出现依赖问题',
              msg = f'{pkg} 缺少依赖 {e.deps}，其中 {faileddeps} 打包失败了。',
            )
          else:
            repo.send_error_report(mod, exc=e, logfile=logfile)

        else:
          build_logger.error(
            'failed', pkgbase = pkg,
            nv_version = newver, pkg_version = version,
            elapsed = elapsed, error = r.error,
          )
          msg = r.error

      if db.USE:
        if r.rusage:
          cputime = r.rusage.cputime
          memory = r.rusage.memory
        else:
          cputime = memory = None
        rs = [r.to_dict() for r in build_reasons[pkg]]
        with db.get_session() as s:
          p = db.PkgLog(
            pkgbase = pkg,
            nv_version = newver,
            pkg_version = version,
            elapsed = elapsed,
            result = r.__class__.__name__,
            cputime = cputime,
            memory = memory,
            msg = msg,
            build_reasons = json.dumps(rs),
          )
          s.add(p)

          stmt = update(
            db.PkgCurrent
          ).where(
            db.PkgCurrent.pkgbase == pkg,
          ).values(
            status = 'done',
          )
          s.execute(stmt)

          db.build_updated(s)

      if r:
        built.add(pkg)
      else:
        failed.add(pkg)

  except KeyboardInterrupt:
    logger.info('keyboard interrupted, bye~')

def main_may_raise(D: Dict[str, Any], pkgs_to_build: List[str]) -> None:
  global DEPMAP

  failed_info = D.get('failed', {})

  if get_git_branch() != 'master':
    raise Exception('repo not on master, aborting.')

  if dburl := config['lilac'].get('dburl'):
    import sqlalchemy
    engine = sqlalchemy.create_engine(dburl)
    db.setup(engine)

  git_reset_hard()
  git_pull_override()
  failed = REPO.load_managed_lilac_and_report()

  depman = DependencyManager(REPO.repodir)
  DEPMAP = get_dependency_map(depman, REPO.mods)

  if pkgs_to_build:
    all_mods = REPO.mods
    REPO.mods = {}
    for pkg_to_build in pkgs_to_build:
      for dep in DEPMAP[pkg_to_build]:
        REPO.mods[dep.pkgname] = all_mods[dep.pkgname]
      REPO.mods[pkg_to_build] = all_mods[pkg_to_build]

  proxy = config['nvchecker'].get('proxy')
  _nvdata, unknown, rebuild = packages_need_update(
    REPO, proxy)
  nvdata.update(_nvdata) # update to the global object

  if pkgs_to_build:
    need_update: Set[str] = set()
    need_rebuild_failed: Set[str] = set()
    need_rebuild_pkgrel: Set[str] = set()
  else:
    U = set(REPO.mods)
    last_commit = D.get('last_commit', EMPTY_COMMIT)
    changed = get_changed_packages(last_commit, 'HEAD') & U

    failed_prev = set(failed_info.keys())
    # no update from upstream, but build instructions have changed; rebuild
    # failed ones
    need_rebuild_failed = failed_prev & changed
    # if pkgrel is updated, build a new release
    need_rebuild_pkgrel = {x for x in changed
                          if pkgrel_changed(last_commit, 'HEAD', x)} - unknown

  updated = {x for x, y in nvdata.items()
              if y.oldver != y.newver}
  failed_updated = {k for k, v in failed_info.items()
                    if k in nvdata and nvdata[k].newver != v}
  # build updated; if last build failed but it gets updated once more,
  # build it again
  need_update = updated | failed_updated
  for p, vers in nvdata.items():
    diff_idxs = [i for i, v in enumerate(vers)
                 if v.oldver != v.newver]
    if diff_idxs:
      mod = REPO.mods[p]
      confs = mod.update_on
      sources = [(i, confs[i]['source']) for i in diff_idxs]
      build_reasons[p].append(BuildReason.NvChecker(sources))

  # rebuild first, update later
  all_building: List[str] = []
  all_building.extend(rebuild)

  all_building.extend(pkgs_to_build)
  for p in pkgs_to_build:
    build_reasons[p].append(BuildReason.Cmdline())

  all_building.extend(need_rebuild_pkgrel)
  for p in need_rebuild_pkgrel:
    build_reasons[p].append(BuildReason.UpdatedPkgrel())

  all_building.extend(need_rebuild_failed)
  for p in need_rebuild_failed:
    build_reasons[p].append(BuildReason.UpdatedFailed())

  all_building.extend(need_update)

  logger.info('these updated (pkgrel) packages should be rebuilt: %r',
              need_rebuild_pkgrel or None)
  logger.info('these previously-failed packages should be rebuilt: %r',
              need_rebuild_failed or None)
  logger.info('these packages are updated as detected by nvchecker: %r',
              need_update or None)
  logger.info('these packages need rebuilding'
              ' as detected by nvchecker or manually specified: %r',
              rebuild or None)

  building_packages.update({x: () for x in all_building})
  update_succeeded: Set[str] = set()

  try:
    build_logger.info('build start')
    if db.USE:
      with db.get_session() as s:
        b = db.Batch(event='start')
        s.add(b)
    start_build(REPO, failed, update_succeeded)
    D['last_commit'] = git_last_commit()
  finally:
    # handle what has been processed even on exception
    failed_info.update({k: nvdata[k].newver for k in failed if k in nvdata})

    for x in update_succeeded:
      if x in failed_info:
        del failed_info[x]
    D['failed'] = failed_info

    if config['lilac']['rebuild_failed_pkgs']:
      if update_succeeded:
        nvtake(update_succeeded, REPO.mods)
    else:
      if need_update or rebuild:
        # only nvtake packages we have tried to build (excluding unbuilt
        # packages due to internal errors)
        built = update_succeeded | failed
        update_nv = built & (need_update | rebuild)
        nvtake(update_nv, REPO.mods)

    build_logger.info('build end')
    if db.USE:
      with db.get_session() as s:
        b = db.Batch(event='stop')
        s.add(b)

    git_reset_hard()
    if config['lilac']['git_push']:
      git_push()

def main(pkgs_to_build: List[str]) -> None:
  store = mydir / 'store'
  with PickledData(store, default={}) as D:
    try:
      main_may_raise(D, pkgs_to_build)
    except Exception:
      tb = traceback.format_exc()
      logger.exception('unexpected error')
      subject = '运行时错误'
      msg = '调用栈如下：\n\n' + tb
      REPO.report_error(subject, msg)

def setup() -> None:
  prctl.set_child_subreaper(1)
  global logdir

  logdir = mydir / 'log' / time.strftime('%Y-%m-%dT%H:%M:%S')
  logdir.mkdir(parents=True, exist_ok=True)
  logfile = logdir / 'lilac-main.log'
  fd = os.open(logfile, os.O_WRONLY | os.O_CREAT, 0o644)
  os.dup2(fd, 1)
  os.dup2(fd, 2)
  os.close(fd)

  enable_pretty_logging('DEBUG')
  if 'MAKEFLAGS' not in os.environ:
    cores = os.cpu_count()
    if cores is not None:
      os.environ['MAKEFLAGS'] = '-j{0}'.format(cores)

  lock_file(mydir / '.lock')

  setup_build_logger()
  os.chdir(REPO.repodir)

  pkgbuild.init_data(PACMAN_DB_DIR)

if __name__ == '__main__':
  try:
    setup()

    main(sys.argv[1:])
  except Exception:
    logger.exception('unexpected error')
